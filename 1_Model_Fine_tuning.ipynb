{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tisRobin/BERT_Research_Project/blob/main/1_Model_Fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8ThmpsZ7pKt"
      },
      "source": [
        "**Reference**:\n",
        "\n",
        "BERT for computational social scientists:\n",
        "\n",
        "https://www.youtube.com/watch?v=UmyOhl9AciI\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg0JuRdA0SDg"
      },
      "source": [
        "* Install the transformers and datasets library "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fz0xH8Z9yZK3",
        "outputId": "57f3c959-894b-4dcf-e2b5-00bd5313ed4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.21.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.7.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjo4TKJ40hcX"
      },
      "source": [
        "* Import the load_dataset function \n",
        "* Import numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kD7-ruSFBklj"
      },
      "outputs": [],
      "source": [
        "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEfup59G0HtB"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LX8o30kj0xCR"
      },
      "source": [
        "* Call the load_dataset function to bring in the \"financial phrasebank\" dataset\n",
        "* the \"financial phrasebank\" dataset is divided into multiple datasets depending on the rate of agreement between the annotators (16). \n",
        "* I chose 'sentences_allagree' for my experiment, which only contains Number of instances with 100% annotator agreement: 2264 out of 4846 sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "440efa30730b4f45a288596a271806eb",
            "f1792d7c049849098b9888b95533a32e",
            "ea6c7987c64e4a079f446f8f976163be",
            "f43e67f249634d37b88e8e14c2df058b",
            "5b6eefa02ce348b5ba6c62e95b68cc58",
            "378e16dc3a6b4c4cb97a547551931234",
            "eeeb673c9c8d4f67b41d52285f0b498d",
            "ef78637d457344d3bffb4412b8661687",
            "89ee3f9def4a42ae91bb2dcd4abbb77a",
            "027ecf85e4c14c1b977198634904a131",
            "982f0325da3141bfbeda719c46f9ab1b"
          ]
        },
        "id": "_kZ6wwDM0uyB",
        "outputId": "25093cd4-e7d5-477d-f7b6-6ef7cec780c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Reusing dataset financial_phrasebank (/root/.cache/huggingface/datasets/financial_phrasebank/sentences_allagree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "440efa30730b4f45a288596a271806eb"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "raw_datasets = load_dataset(\"financial_phrasebank\", \"sentences_allagree\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8uqPR0N3wuH"
      },
      "source": [
        "* The dataset has two columns, containing the sentence and the corresponding sentiment respectively.\n",
        "\n",
        "* Unlike many other datasets in huggingface, there is no train/validation/test split for the dataset, Therfore, it needs to be done manually. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzb50d183nQd",
        "outputId": "7ca035e5-9271-44c0-b76a-738119235422"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['sentence', 'label'],\n",
              "        num_rows: 2264\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "raw_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJTFsuX65R2d",
        "outputId": "58167465-ca6e-443c-b0ae-dc686e752a2c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['_TF_DATASET_REFS',\n",
              " '__class__',\n",
              " '__del__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__enter__',\n",
              " '__eq__',\n",
              " '__exit__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getitem__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__iter__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_build_local_temp_path',\n",
              " '_check_index_is_initialized',\n",
              " '_data',\n",
              " '_fingerprint',\n",
              " '_format_columns',\n",
              " '_format_kwargs',\n",
              " '_format_type',\n",
              " '_get_cache_file_path',\n",
              " '_get_output_signature',\n",
              " '_getitem',\n",
              " '_indexes',\n",
              " '_indices',\n",
              " '_info',\n",
              " '_iter',\n",
              " '_map_single',\n",
              " '_new_dataset_with_indices',\n",
              " '_output_all_columns',\n",
              " '_push_parquet_shards_to_hub',\n",
              " '_select_contiguous',\n",
              " '_select_with_indices_mapping',\n",
              " '_split',\n",
              " 'add_column',\n",
              " 'add_elasticsearch_index',\n",
              " 'add_faiss_index',\n",
              " 'add_faiss_index_from_external_arrays',\n",
              " 'add_item',\n",
              " 'align_labels_with_mapping',\n",
              " 'builder_name',\n",
              " 'cache_files',\n",
              " 'cast',\n",
              " 'cast_column',\n",
              " 'citation',\n",
              " 'class_encode_column',\n",
              " 'cleanup_cache_files',\n",
              " 'column_names',\n",
              " 'config_name',\n",
              " 'data',\n",
              " 'dataset_size',\n",
              " 'description',\n",
              " 'download_checksums',\n",
              " 'download_size',\n",
              " 'drop_index',\n",
              " 'export',\n",
              " 'features',\n",
              " 'filter',\n",
              " 'flatten',\n",
              " 'flatten_indices',\n",
              " 'format',\n",
              " 'formatted_as',\n",
              " 'from_buffer',\n",
              " 'from_csv',\n",
              " 'from_dict',\n",
              " 'from_file',\n",
              " 'from_json',\n",
              " 'from_pandas',\n",
              " 'from_parquet',\n",
              " 'from_text',\n",
              " 'get_index',\n",
              " 'get_nearest_examples',\n",
              " 'get_nearest_examples_batch',\n",
              " 'homepage',\n",
              " 'info',\n",
              " 'is_index_initialized',\n",
              " 'license',\n",
              " 'list_indexes',\n",
              " 'load_elasticsearch_index',\n",
              " 'load_faiss_index',\n",
              " 'load_from_disk',\n",
              " 'map',\n",
              " 'num_columns',\n",
              " 'num_rows',\n",
              " 'prepare_for_task',\n",
              " 'push_to_hub',\n",
              " 'remove_columns',\n",
              " 'rename_column',\n",
              " 'rename_columns',\n",
              " 'reset_format',\n",
              " 'save_faiss_index',\n",
              " 'save_to_disk',\n",
              " 'search',\n",
              " 'search_batch',\n",
              " 'select',\n",
              " 'set_format',\n",
              " 'set_transform',\n",
              " 'shape',\n",
              " 'shard',\n",
              " 'shuffle',\n",
              " 'size_in_bytes',\n",
              " 'sort',\n",
              " 'split',\n",
              " 'supervised_keys',\n",
              " 'task_templates',\n",
              " 'to_csv',\n",
              " 'to_dict',\n",
              " 'to_json',\n",
              " 'to_pandas',\n",
              " 'to_parquet',\n",
              " 'to_tf_dataset',\n",
              " 'train_test_split',\n",
              " 'unique',\n",
              " 'version',\n",
              " 'with_format',\n",
              " 'with_transform']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "dir(raw_datasets['train'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngmMFBDz6bzD",
        "outputId": "eeafa762-08d1-4769-d52f-20c37da2fd5c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MemoryMappedTable\n",
              "sentence: string\n",
              "label: int64\n",
              "----\n",
              "sentence: [[\"According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .\",\"For the last quarter of 2010 , Componenta 's net sales doubled to EUR131m from EUR76m for the same period a year earlier , while it moved to a zero pre-tax profit from a pre-tax loss of EUR7m .\",\"In the third quarter of 2010 , net sales increased by 5.2 % to EUR 205.5 mn , and operating profit by 34.9 % to EUR 23.5 mn .\",\"Operating profit rose to EUR 13.1 mn from EUR 8.7 mn in the corresponding period in 2007 representing 7.7 % of net sales .\",\"Operating profit totalled EUR 21.1 mn , up from EUR 18.6 mn in 2007 , representing 9.7 % of net sales .\",\"Finnish Talentum reports its operating profit increased to EUR 20.5 mn in 2005 from EUR 9.3 mn in 2004 , and net sales totaled EUR 103.3 mn , up from EUR 96.4 mn .\",\"Clothing retail chain Sepp+ñl+ñ 's sales increased by 8 % to EUR 155.2 mn , and operating profit rose to EUR 31.1 mn from EUR 17.1 mn in 2004 .\",\"Consolidated net sales increased 16 % to reach EUR74 .8 m , while operating profit amounted to EUR0 .9 m compared to a loss of EUR0 .7 m in the prior year period .\",\"Foundries division reports its sales increased by 9.7 % to EUR 63.1 mn from EUR 57.5 mn in the corresponding period in 2006 , and sales of the Machine Shop division increased by 16.4 % to EUR 41.2 mn from EUR 35.4 mn in the corresponding period in 2006 .\",\"HELSINKI ( AFX ) - Shares closed higher , led by Nokia after it announced plans to team up with Sanyo to manufacture 3G handsets , and by Nokian Tyres after its fourth-quarter earnings report beat analysts ' expectations , dealers said .\",...,\"Comparable operating profit totaled EUR 4.7 mn , down from EUR 5.1 mn in the corresponding period in 2005 , representing 7.4 % of net sales .\",\"In Finland 's Hobby Hall 's sales decreased by 10 % , and international sales fell by 19 % .\",\"In the Baltic states the company reports net sales of EUR 11.9 mn , down from EUR 14.2 mn , and an operative EBIT of EUR -2.2 mn , down from EUR -1.7 mn .\",\"Operating profits in the half were  0.8 m , down from  0.9 m as Glisten invested in the brand and the management team .\",\"Sales in Finland decreased by 2.0 % , and international sales decreased by 9.3 % in terms of euros , and by 15.1 % in terms of local currencies .\",\"Operating result for the 12-month period decreased from the profit of EUR0 .4 m while turnover decreased from EUR5 .6 m , as compared to 2004 .\",\"HELSINKI Thomson Financial - Shares in Cargotec fell sharply in early afternoon trade after the cargo handling group posted a surprise drop in April-June profits , which overshadowed the large number of new orders received during the three months .\",\"LONDON MarketWatch -- Share prices ended lower in London Monday as a rebound in bank stocks failed to offset broader weakness for the FTSE 100 .\",\"Operating profit fell to EUR 35.4 mn from EUR 68.8 mn in 2007 , including vessel sales gain of EUR 12.3 mn .\",\"Sales in Finland decreased by 10.5 % in January , while sales outside Finland dropped by 17 % .\"]]\n",
              "label: [[1,2,2,2,2,2,2,2,2,2,...,0,0,0,0,0,0,0,0,0,0]]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "raw_datasets['train'].data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RldxAqXX7J7s",
        "outputId": "e0b34a77-5081-4b0a-ed70-2d719f0b76cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 1,\n",
              " 'sentence': 'According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "raw_datasets['train'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNiswHM85yyy"
      },
      "outputs": [],
      "source": [
        "split_data = raw_datasets['train'].train_test_split(train_size=int(2264*0.8) , test_size = 2264 - int(2264*0.8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzs6Tc698gwR",
        "outputId": "b791d451-8876-4fe6-f592-44fba03b8fb5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['sentence', 'label'],\n",
              "        num_rows: 1811\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['sentence', 'label'],\n",
              "        num_rows: 453\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "split_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDf9VNfwrc9j",
        "outputId": "051f5da8-1e78-4bbb-9ab6-89be64621b86"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['sentence', 'label'],\n",
              "    num_rows: 1811\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "split_data['train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VUPRRq2-c5C",
        "outputId": "9264028f-0c82-4db1-ddee-c145af03223b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['sentence', 'label'],\n",
              "    num_rows: 453\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "split_data['test']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKLuTAi_o2z1"
      },
      "source": [
        "* Divide the data further into 4 categories "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzrc4z9eAGCC"
      },
      "outputs": [],
      "source": [
        "train_texts = split_data['train']['sentence']\n",
        "train_labels = split_data['train']['label']\n",
        "test_texts = split_data['test']['sentence']\n",
        "test_labels = split_data['test']['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMYgz0NMAqxr",
        "outputId": "4d18942d-05f9-42cc-c009-c33242887fbe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1811, 1811, 453, 453)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "len(train_texts), len(train_labels), len(test_texts), len(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_7uNfMkAuMh",
        "outputId": "aa0385a3-009b-4121-87a7-04bcabb45374"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2,\n",
              " 'Circulation revenue has increased by 5 % in Finland and 4 % in Sweden in 2008 .')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# example\n",
        "train_labels[0], train_texts[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pz-I3aBW_OZt"
      },
      "outputs": [],
      "source": [
        "model_name = 'distilbert-base-cased'  \n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qk0TlK6kKCH"
      },
      "source": [
        "* Padding, truncation, special tokens, division into word pieces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxsppFTcCfFT"
      },
      "outputs": [],
      "source": [
        "# The maximum number of tokens in any document sent to BERT.\n",
        "max_length = 512   \n",
        "\n",
        "# tokenize the train and test text according to the BERT tokenizer \n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=max_length)\n",
        "test_encodings  = tokenizer(test_texts, truncation=True, padding=True, max_length=max_length)\n",
        "\n",
        "# Since the labels were already encoded into integers, I simply passed along the same values.\n",
        "train_labels_encoded = train_labels\n",
        "test_labels_encoded  = test_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZDBbp_nDfII",
        "outputId": "b80f7085-b17e-41ff-b281-a1daef541d10"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({0, 1, 2}, {0, 1, 2})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "set(train_labels_encoded), set(test_labels_encoded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWl2KSZFmyv1"
      },
      "source": [
        "* Convert labels and data into Torch dataset object (since this is what Huggingface accpets)\n",
        "\n",
        "https://huggingface.co/transformers/v3.4.0/custom_datasets.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbIJU48cDhtL"
      },
      "outputs": [],
      "source": [
        "class MyDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "# this __getitem__ Dunder method is what convets the data into torch objects when passed into BERT.\n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        # add the converted label of the corresponding text \n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5J-LFGHiEH0J"
      },
      "outputs": [],
      "source": [
        "# instantiate\n",
        "train_dataset = MyDataset(train_encodings, train_labels_encoded)\n",
        "test_dataset = MyDataset(test_encodings, test_labels_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgvUeTjDqWUE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-JZLlpWqc8N"
      },
      "source": [
        "  Index \n",
        "  \n",
        "    * 0   - [PAD]\n",
        "    * 101 - [CLS] - classification token\n",
        "    * 102 - [SEP] - separator token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5TBCuwDzM6M"
      },
      "source": [
        "https://huggingface.co/docs/transformers/glossary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "6c5gyXqSEO9S",
        "outputId": "18f03419-19ad-4d66-82c1-87248cf34a3d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[CLS] C ##ir ##cula ##tion revenue has increased by 5 % in Finland and 4 % in Sweden in 2008 . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# sample of tokenized instance\n",
        "' '.join(train_dataset.encodings[0].tokens[0:100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvM1lc0fnOel"
      },
      "source": [
        "* Employ DistilBert, a smaller version of BERT \n",
        "\n",
        "\n",
        "The attention network in DistilBertForSequenceClassification is designed so that the indexes of the final [CLS ] embedding score output (this is called 'logits') correspond to the annotated numbers. That is why if the annotated sentiment is a string, they usually need to be encoded into numbers. \n",
        "\n",
        "\n",
        "This can also be seen in the output of the code below. \n",
        "\n",
        "\"id2label\": {\n",
        "    \"0\": \"LABEL_0\",\n",
        "    \"1\": \"LABEL_1\",\n",
        "    \"2\": \"LABEL_2\"\n",
        "}\n",
        "\n",
        "\n",
        "For example, when the highest embedding score is located on index '0', the model would output \"LABEL_0\", which we would interpret as 'negative'. So the model would be trained to produce the highest embedding score for the index corresponding to the encoded annotation. \n",
        "\n",
        "This is why we see 'np.argmax()' in the custom metric definition below. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSVE6NQlEYBx",
        "outputId": "94cf39df-4baa-4959-fbed-54083f647759"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEP-V3_6E6Fr"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    num_train_epochs=3,              # total number of training epochs\n",
        "    per_device_train_batch_size=16,  # batch size per device during training\n",
        "    per_device_eval_batch_size=20,   # batch size for evaluation\n",
        "    learning_rate=5e-5,              # initial learning rate for Adam optimizer\n",
        "    warmup_steps=100,                # number of warmup steps for learning rate scheduler (set lower because of small dataset size)\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    output_dir='./results',          # output directory\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=100,               # number of steps to output logging (set lower because of small dataset size)\n",
        "    evaluation_strategy='epoch',     # evaluate during fine-tuning so that we can see progress\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXX0DuV-H7qM"
      },
      "outputs": [],
      "source": [
        "from datasets import load_metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5J-g-9NEuv3A"
      },
      "source": [
        "More on Logits and argmax for custom metric functions (Stackoverflow): \n",
        "\n",
        "\n",
        "Usually logits is the output tensor of a classification network (the output of [CLS] token embedding going through BERTForSequenceClassification), whose content is the unnormalized (not scaled between 0 and 1) probabilities.\n",
        "\n",
        "np.argmax gives you the index of maximum value along the specified axis, which corresponds to the class that you are trying to predict. \n",
        "\n",
        "For instance, let's say that a logits output looks like the following:\n",
        "\n",
        "logits = [ [ 10, 500, -1, 0.5, 12 ] ]\n",
        "\n",
        "The tensor shape is [1, 5]. Just looking at the tensor values, you can easily understand that the class with the highest probability is the one associated to the position 1, with value 500.\n",
        "\n",
        "How can you extract the position of the highest value? You can use argmax. \n",
        "\n",
        "top = np.argmax(logits, -1)\n",
        "Once executed it will return the value 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqiO366_E6uY"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    metric1 = load_metric(\"precision\")\n",
        "    metric2 = load_metric(\"recall\")\n",
        "    metric3 = load_metric(\"accuracy\")\n",
        "    metric4 = load_metric(\"f1\")\n",
        "\n",
        "    \n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    precision = metric1.compute(predictions=predictions, references=labels, average=\"weighted\")[\"precision\"]\n",
        "    recall = metric2.compute(predictions=predictions, references=labels, average=\"weighted\")[\"recall\"]\n",
        "    accuracy = metric3.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
        "    f1 = metric4.compute(predictions=predictions, references=labels, average=\"weighted\")[\"f1\"]\n",
        "    return {\"precision\": precision, \"recall\": recall, \"accuracy\": accuracy, \"f1\": f1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBThBsSJI1Oz"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=test_dataset,           # evaluation dataset \n",
        "    compute_metrics=compute_metrics      # our custom evaluation function \n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBbCUcYK3C_s"
      },
      "source": [
        "After more than 3 epochs, the validation loss tends to increase again, which implies overfitting. So I set the epoch to 3. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "id": "_4hbxKm4JBqm",
        "outputId": "81d736e8-2e80-456a-8803-05ebc9b38e57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 1811\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 342\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='342' max='342' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [342/342 1:59:11, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.704800</td>\n",
              "      <td>0.122034</td>\n",
              "      <td>0.962093</td>\n",
              "      <td>0.962472</td>\n",
              "      <td>0.962472</td>\n",
              "      <td>0.961894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.160700</td>\n",
              "      <td>0.076482</td>\n",
              "      <td>0.975665</td>\n",
              "      <td>0.975717</td>\n",
              "      <td>0.975717</td>\n",
              "      <td>0.975665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.053100</td>\n",
              "      <td>0.075605</td>\n",
              "      <td>0.984522</td>\n",
              "      <td>0.984547</td>\n",
              "      <td>0.984547</td>\n",
              "      <td>0.984491</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 453\n",
            "  Batch size = 20\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 453\n",
            "  Batch size = 20\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 453\n",
            "  Batch size = 20\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=342, training_loss=0.27392478086795025, metrics={'train_runtime': 7172.7785, 'train_samples_per_second': 0.757, 'train_steps_per_second': 0.048, 'total_flos': 132133929481404.0, 'train_loss': 0.27392478086795025, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwBNbaQl78ol"
      },
      "source": [
        "* Save model for reuse "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbrXJnIH_AKG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78d57cac-d340-45b6-e8f2-f09be44aef8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to distilbert_platform_growth\n",
            "Configuration saved in distilbert_platform_growth/config.json\n",
            "Model weights saved in distilbert_platform_growth/pytorch_model.bin\n"
          ]
        }
      ],
      "source": [
        "trainer.save_model(\"distilbert_platform_growth\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "440efa30730b4f45a288596a271806eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f1792d7c049849098b9888b95533a32e",
              "IPY_MODEL_ea6c7987c64e4a079f446f8f976163be",
              "IPY_MODEL_f43e67f249634d37b88e8e14c2df058b"
            ],
            "layout": "IPY_MODEL_5b6eefa02ce348b5ba6c62e95b68cc58"
          }
        },
        "f1792d7c049849098b9888b95533a32e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_378e16dc3a6b4c4cb97a547551931234",
            "placeholder": "​",
            "style": "IPY_MODEL_eeeb673c9c8d4f67b41d52285f0b498d",
            "value": "100%"
          }
        },
        "ea6c7987c64e4a079f446f8f976163be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef78637d457344d3bffb4412b8661687",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_89ee3f9def4a42ae91bb2dcd4abbb77a",
            "value": 1
          }
        },
        "f43e67f249634d37b88e8e14c2df058b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_027ecf85e4c14c1b977198634904a131",
            "placeholder": "​",
            "style": "IPY_MODEL_982f0325da3141bfbeda719c46f9ab1b",
            "value": " 1/1 [00:00&lt;00:00, 15.12it/s]"
          }
        },
        "5b6eefa02ce348b5ba6c62e95b68cc58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "378e16dc3a6b4c4cb97a547551931234": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eeeb673c9c8d4f67b41d52285f0b498d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef78637d457344d3bffb4412b8661687": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89ee3f9def4a42ae91bb2dcd4abbb77a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "027ecf85e4c14c1b977198634904a131": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "982f0325da3141bfbeda719c46f9ab1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}